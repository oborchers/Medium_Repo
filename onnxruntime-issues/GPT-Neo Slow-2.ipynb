{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e73c7675",
   "metadata": {},
   "source": [
    "# Putting Transformers into Production with ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97aca869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: transformers 4.4.2\n",
      "Uninstalling transformers-4.4.2:\n",
      "  Successfully uninstalled transformers-4.4.2\n",
      "Collecting git+https://github.com/huggingface/transformers.git\n",
      "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-vdtpwnfh\n",
      "  Running command git clone -q https://github.com/huggingface/transformers.git /tmp/pip-req-build-vdtpwnfh\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from transformers==4.5.0.dev0) (20.9)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.5.0.dev0) (3.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.5.0.dev0) (2021.3.17)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers==4.5.0.dev0) (4.59.0)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.8/dist-packages (from transformers==4.5.0.dev0) (0.0.43)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==4.5.0.dev0) (2.25.1)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.5.0.dev0) (0.10.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.5.0.dev0) (1.19.5)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->transformers==4.5.0.dev0) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.5.0.dev0) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.5.0.dev0) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.5.0.dev0) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.5.0.dev0) (1.26.4)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==4.5.0.dev0) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==4.5.0.dev0) (1.0.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==4.5.0.dev0) (1.15.0)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.5.0.dev0-py3-none-any.whl size=2059073 sha256=76b22162e22013b9b66ec2e3c75e629b83bae4050e9859f4ad6930cc83964b79\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-z87apk99/wheels/05/0a/97/64ae47c27ba95fae2cb5838e7b4b7247a34d4a8ba5f7092de2\n",
      "Successfully built transformers\n",
      "Installing collected packages: transformers\n",
      "Successfully installed transformers-4.5.0.dev0\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence-transformers-1.0.4.tar.gz (74 kB)\n",
      "\u001b[K     |████████████████████████████████| 74 kB 4.6 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (1.1.0)\n",
      "Collecting IProgress\n",
      "  Downloading IProgress-0.4-py3-none-any.whl (11 kB)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.5.zip (1.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 11.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from IProgress) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from nltk) (2021.3.17)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.59.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (4.5.0.dev0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (1.8.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (1.19.5)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (0.24.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (1.6.2)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.95-cp38-cp38-manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 39.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2.25.1)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.0.43)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.10.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.12)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (20.9)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (4.0.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sentence-transformers) (2.1.0)\n",
      "Building wheels for collected packages: nltk, sentence-transformers\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nltk: filename=nltk-3.5-py3-none-any.whl size=1434675 sha256=8decf5b65a5f289410b20eea757b5f766e8fe3337337798024c289de267fbf75\n",
      "  Stored in directory: /root/.cache/pip/wheels/ff/d5/7b/f1fb4e1e1603b2f01c2424dd60fbcc50c12ef918bafc44b155\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-1.0.4-py3-none-any.whl size=114306 sha256=d3bbfa77675c26f2d6eedd6c13895f9173ae30d3204a23d8c39e362d7d14a9c1\n",
      "  Stored in directory: /root/.cache/pip/wheels/28/cb/ae/360fe121dc748add4fabecd46e78c31d1ea2402d341f97e2dc\n",
      "Successfully built nltk sentence-transformers\n",
      "Installing collected packages: sentencepiece, nltk, sentence-transformers, IProgress\n",
      "Successfully installed IProgress-0.4 nltk-3.5 sentence-transformers-1.0.4 sentencepiece-0.1.95\n",
      "Collecting onnxruntime-gpu\n",
      "  Downloading onnxruntime_gpu-1.7.0-cp38-cp38-manylinux2014_x86_64.whl (29.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 29.9 MB 10.0 MB/s eta 0:00:01    |███▏                            | 2.9 MB 10.0 MB/s eta 0:00:03     |███████                         | 6.4 MB 10.0 MB/s eta 0:00:03\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.8/dist-packages (from onnxruntime-gpu) (1.19.5)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from onnxruntime-gpu) (3.15.6)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.8/dist-packages (from protobuf->onnxruntime-gpu) (1.15.0)\n",
      "Installing collected packages: onnxruntime-gpu\n",
      "Successfully installed onnxruntime-gpu-1.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y transformers\n",
    "!pip install -U git+https://github.com/huggingface/transformers.git\n",
    "!pip install sentence-transformers termcolor IProgress nltk\n",
    "!pip install onnxruntime-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac549753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX Runtime Execution Providers: \n",
      "['CUDAExecutionProvider', 'CPUExecutionProvider']\n"
     ]
    }
   ],
   "source": [
    "!echo \"ONNX Runtime Execution Providers: \" && python -c \"import onnxruntime as ort; print(ort.get_available_providers())\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9dec733",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /root/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1\n",
      "1.7.0\n",
      "4.5.0.dev0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping corpora/brown.zip.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import onnx\n",
    "import onnxruntime as rt\n",
    "import multiprocessing\n",
    "import transformers\n",
    "import time\n",
    "import nltk\n",
    "\n",
    "from termcolor import colored\n",
    "from transformers import convert_graph_to_onnx\n",
    "from pathlib import Path\n",
    "from onnxruntime_customops import get_library_path\n",
    "\n",
    "nltk.download(\"brown\")\n",
    "\n",
    "print(onnx.__version__)\n",
    "print(rt.__version__)\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c142926e",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = rt.SessionOptions()\n",
    "opt.register_custom_ops_library(get_library_path())\n",
    "opt.graph_optimization_level = rt.GraphOptimizationLevel.ORT_ENABLE_EXTENDED\n",
    "opt.log_severity_level = 4\n",
    "opt.intra_op_num_threads = multiprocessing.cpu_count()\n",
    "opt.execution_mode = rt.ExecutionMode.ORT_SEQUENTIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc75fdd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mGPU available True\u001b[0m\n",
      "\u001b[32mGPU Name: Tesla V100-SXM2-32GB\u001b[0m\n",
      "\u001b[32mGPU Count: 1\u001b[0m\n",
      "\u001b[32mCORE Count: 48\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(colored(f\"GPU available {torch.cuda.is_available()}\", \"green\"))\n",
    "print(colored(f\"GPU Name: {torch.cuda.get_device_name(0)}\", \"green\"))\n",
    "print(colored(f\"GPU Count: {torch.cuda.device_count()}\", \"green\"))\n",
    "print(colored(f\"CORE Count: {multiprocessing.cpu_count()}\", \"green\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30715ee5",
   "metadata": {},
   "source": [
    "## Simple Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adfa63f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"EleutherAI/gpt-neo-1.3B\"\n",
    "pipeline_name = \"text-generation\"\n",
    "\n",
    "model_pth = Path(f\"gpt_neo/gpt_neo_13b.onnx\")\n",
    "model_pth.parent.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e48f19b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found input input_ids with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found input attention_mask with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_0 with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_1 with shape: {0: 'batch', 2: 'sequence'}\n",
      "Found output output_1 with shape: {0: 'batch', 2: 'sequence'}\n",
      "Found output output_2 with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_3 with shape: {0: 'batch', 2: 'sequence'}\n",
      "Found output output_3 with shape: {0: 'batch', 2: 'sequence'}\n",
      "Found output output_4 with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_5 with shape: {0: 'batch', 2: 'sequence'}\n",
      "Found output output_5 with shape: {0: 'batch', 2: 'sequence'}\n",
      "Found output output_6 with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_7 with shape: {0: 'batch', 2: 'sequence'}\n",
      "Found output output_7 with shape: {0: 'batch', 2: 'sequence'}\n",
      "Found output output_8 with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_9 with shape: {0: 'batch', 2: 'sequence'}\n",
      "Found output output_9 with shape: {0: 'batch', 2: 'sequence'}\n",
      "Found output output_10 with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_11 with shape: {0: 'batch', 2: 'sequence'}\n",
      "Found output output_11 with shape: {0: 'batch', 2: 'sequence'}\n",
      "Found output output_12 with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_13 with shape: {0: 'batch', 2: 'sequence'}\n",
      "Found output output_13 with shape: {0: 'batch', 2: 'sequence'}\n",
      "Found output output_14 with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_15 with shape: {0: 'batch', 2: 'sequence'}\n",
      "Found output output_15 with shape: {0: 'batch', 2: 'sequence'}\n",
      "Found output output_16 with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_17 with shape: {0: 'batch', 2: 'sequence'}\n",
      "Found output output_17 with shape: {0: 'batch', 2: 'sequence'}\n",
      "Found output output_18 with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_19 with shape: {0: 'batch', 2: 'sequence'}\n",
      "Found output output_19 with shape: {0: 'batch', 2: 'sequence'}\n",
      "Found output output_20 with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_21 with shape: {0: 'batch', 2: 'sequence'}\n",
      "Found output output_21 with shape: {0: 'batch', 2: 'sequence'}\n",
      "Found output output_22 with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_23 with shape: {0: 'batch', 2: 'sequence'}\n",
      "Found output output_23 with shape: {0: 'batch', 2: 'sequence'}\n",
      "Found output output_24 with shape: {0: 'batch', 1: 'sequence'}\n",
      "Ensuring inputs are in correct order\n",
      "past_key_values is not present in the generated input list.\n",
      "Generated inputs order: ['input_ids']\n"
     ]
    }
   ],
   "source": [
    "nlp = transformers.pipeline(pipeline_name, model=model_name, tokenizer=model_name, device=-1)\n",
    "with torch.no_grad():\n",
    "    (\n",
    "        input_names,\n",
    "        output_names,\n",
    "        dynamic_axes,\n",
    "        tokens,\n",
    "    ) = convert_graph_to_onnx.infer_shapes(nlp, \"pt\")\n",
    "    ordered_input_names, model_args = convert_graph_to_onnx.ensure_valid_input(\n",
    "        nlp.model, tokens, input_names\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a069362",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp = transformers.pipeline(pipeline_name, model=model_name, tokenizer=model_name, device=0)\n",
    "tokenizer = nlp.tokenizer\n",
    "model = nlp.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36679bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENTENCES = 1_000\n",
    "\n",
    "sents = [\" \".join(sent) for sent in nltk.corpus.brown.sents()][:MAX_SENTENCES]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35e9821",
   "metadata": {},
   "source": [
    "## Baseline: Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13b2f925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting 1000 sentences took 53s at 18 sentences/s.\n"
     ]
    }
   ],
   "source": [
    "# We just want the logits, not the full pipeline\n",
    "start = time.time()\n",
    "for sent in sents:\n",
    "    inp = tokenizer(sent, return_tensors=\"pt\")\n",
    "    for key, value in inp.items():\n",
    "        inp[key] = value.to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        _ = nlp.model.forward(**inp).logits\n",
    "\n",
    "duration = int(time.time() - start)\n",
    "speed = int(MAX_SENTENCES / duration)\n",
    "print(f\"predicting {MAX_SENTENCES} sentences took {duration}s at {speed} sentences/s.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9f0a91",
   "metadata": {},
   "source": [
    "## Build custom model to ease exporting\n",
    "\n",
    "This step may take really long!! Beware that this may take over **1 hour**. I am using a pre-stored model I exported over night."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de54c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTNeoSent(transformers.GPTNeoForCausalLM):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.sentence_embedding = torch.nn.Identity()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        return self.sentence_embedding(\n",
    "            super().forward(input_ids, attention_mask=attention_mask).logits\n",
    "        )\n",
    "# Create the new model based on the config of the original pipeline\n",
    "model = GPTNeoSent(config=nlp.model.config).from_pretrained(model_name)\n",
    "\n",
    "encoding = nlp.tokenizer([\"hello my friends!\"], return_tensors=\"pt\")\n",
    "\n",
    "if not model_pth.exists():\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        (encoding[\"input_ids\"], encoding[\"attention_mask\"]),\n",
    "        f=model_pth.as_posix(),\n",
    "        input_names=input_names,\n",
    "        output_names=output_names,\n",
    "        dynamic_axes=dynamic_axes,\n",
    "        do_constant_folding=True,\n",
    "        use_external_data_format=True, # Needed because of model size\n",
    "        enable_onnx_checker=True,\n",
    "        opset_version=12,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a686a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt_neo/\n",
      "gpt_neo/transformer.h.4.attn.attention.bias\n",
      "gpt_neo/154931\n",
      "gpt_neo/150389\n",
      "gpt_neo/transformer.h.1.attn.attention.out_proj.bias\n",
      "gpt_neo/transformer.h.23.ln_1.bias\n",
      "gpt_neo/154935\n",
      "gpt_neo/161766\n",
      "gpt_neo/148101\n",
      "gpt_neo/145833\n",
      "gpt_neo/transformer.h.15.ln_1.weight\n",
      "gpt_neo/143554\n",
      "gpt_neo/transformer.h.19.ln_1.bias\n",
      "gpt_neo/159501\n",
      "gpt_neo/136712\n",
      "gpt_neo/transformer.wpe.weight\n",
      "gpt_neo/152654\n",
      "gpt_neo/152666\n",
      "gpt_neo/transformer.h.23.ln_2.bias\n",
      "gpt_neo/transformer.h.4.attn.attention.out_proj.bias\n",
      "gpt_neo/transformer.h.17.attn.attention.out_proj.bias\n",
      "gpt_neo/152670\n",
      "gpt_neo/transformer.h.23.ln_2.weight\n",
      "gpt_neo/transformer.h.9.mlp.c_proj.bias\n",
      "gpt_neo/141267\n",
      "gpt_neo/transformer.h.11.ln_2.weight\n",
      "gpt_neo/150380\n",
      "gpt_neo/transformer.h.20.mlp.c_proj.bias\n",
      "gpt_neo/148110\n",
      "gpt_neo/transformer.h.21.mlp.c_fc.bias\n",
      "gpt_neo/157214\n",
      "gpt_neo/transformer.h.22.attn.attention.out_proj.bias\n",
      "gpt_neo/transformer.h.10.attn.attention.bias\n",
      "gpt_neo/transformer.h.6.ln_1.weight\n",
      "gpt_neo/transformer.h.13.ln_1.weight\n",
      "gpt_neo/143558\n",
      "gpt_neo/161778\n",
      "gpt_neo/161770\n",
      "gpt_neo/transformer.h.14.mlp.c_fc.bias\n",
      "gpt_neo/161765\n",
      "gpt_neo/transformer.h.2.mlp.c_fc.bias\n",
      "gpt_neo/148111\n",
      "gpt_neo/161769\n",
      "gpt_neo/150391\n",
      "gpt_neo/transformer.h.15.mlp.c_proj.bias\n",
      "gpt_neo/transformer.h.2.attn.attention.out_proj.bias\n",
      "gpt_neo/transformer.h.14.ln_2.bias\n",
      "gpt_neo/transformer.h.3.mlp.c_proj.bias\n",
      "gpt_neo/transformer.h.13.ln_2.bias\n",
      "gpt_neo/transformer.h.16.ln_1.weight\n",
      "gpt_neo/154936\n",
      "gpt_neo/154946\n",
      "gpt_neo/transformer.h.5.ln_1.weight\n",
      "gpt_neo/transformer.h.10.attn.attention.out_proj.bias\n",
      "gpt_neo/transformer.h.11.attn.attention.out_proj.bias\n",
      "gpt_neo/transformer.h.20.ln_1.bias\n",
      "gpt_neo/transformer.h.4.ln_1.weight\n",
      "gpt_neo/138989\n",
      "gpt_neo/transformer.h.8.attn.attention.bias\n",
      "gpt_neo/143556\n",
      "gpt_neo/transformer.h.11.ln_2.bias\n",
      "gpt_neo/143555\n",
      "gpt_neo/154944\n",
      "gpt_neo/141276\n",
      "gpt_neo/148098\n",
      "gpt_neo/136724\n",
      "gpt_neo/136725\n",
      "gpt_neo/164044\n",
      "gpt_neo/transformer.h.5.attn.attention.out_proj.bias\n",
      "gpt_neo/transformer.h.16.ln_2.weight\n",
      "gpt_neo/transformer.h.6.attn.attention.out_proj.bias\n",
      "gpt_neo/148102\n",
      "gpt_neo/141268\n",
      "gpt_neo/161782\n",
      "gpt_neo/transformer.h.2.ln_2.bias\n",
      "gpt_neo/transformer.h.1.mlp.c_fc.bias\n",
      "gpt_neo/transformer.h.22.mlp.c_proj.bias\n",
      "gpt_neo/161779\n",
      "gpt_neo/161768\n",
      "gpt_neo/transformer.h.5.ln_2.bias\n",
      "gpt_neo/transformer.h.18.ln_2.bias\n",
      "gpt_neo/transformer.h.22.ln_1.bias\n",
      "gpt_neo/136722\n",
      "gpt_neo/transformer.h.12.ln_1.bias\n",
      "gpt_neo/145832\n",
      "gpt_neo/transformer.h.13.attn.attention.out_proj.bias\n",
      "gpt_neo/143542\n",
      "gpt_neo/transformer.h.17.mlp.c_fc.bias\n",
      "gpt_neo/transformer.h.10.ln_1.weight\n",
      "gpt_neo/transformer.h.18.attn.attention.out_proj.bias\n",
      "gpt_neo/transformer.h.4.ln_1.bias\n",
      "gpt_neo/transformer.h.14.attn.attention.bias\n",
      "gpt_neo/159505\n",
      "gpt_neo/transformer.wte.weight\n",
      "gpt_neo/transformer.h.11.mlp.c_proj.bias\n",
      "gpt_neo/transformer.h.19.mlp.c_fc.bias\n",
      "gpt_neo/transformer.h.16.mlp.c_proj.bias\n",
      "gpt_neo/transformer.h.4.mlp.c_fc.bias\n",
      "gpt_neo/159504\n",
      "gpt_neo/transformer.h.2.ln_1.bias\n",
      "gpt_neo/150393\n",
      "gpt_neo/transformer.h.3.ln_2.bias\n",
      "gpt_neo/transformer.h.16.attn.attention.out_proj.bias\n",
      "gpt_neo/141263\n",
      "gpt_neo/transformer.h.14.mlp.c_proj.bias\n",
      "gpt_neo/transformer.h.8.attn.attention.out_proj.bias\n",
      "gpt_neo/transformer.h.8.ln_2.weight\n",
      "gpt_neo/161781\n",
      "gpt_neo/157226\n",
      "gpt_neo/152657\n",
      "gpt_neo/transformer.h.14.attn.attention.out_proj.bias\n",
      "gpt_neo/transformer.h.19.mlp.c_proj.bias\n",
      "gpt_neo/transformer.h.9.ln_1.weight\n",
      "gpt_neo/145821\n",
      "gpt_neo/transformer.h.1.ln_2.weight\n",
      "gpt_neo/gpt_neo_13b.onnx\n",
      "gpt_neo/transformer.h.18.ln_1.weight\n",
      "gpt_neo/136710\n",
      "gpt_neo/transformer.h.3.ln_2.weight\n",
      "gpt_neo/transformer.h.20.ln_1.weight\n",
      "gpt_neo/transformer.h.8.ln_1.bias\n",
      "gpt_neo/transformer.h.16.ln_1.bias\n",
      "gpt_neo/transformer.h.9.ln_2.weight\n",
      "gpt_neo/159488\n",
      "gpt_neo/transformer.h.12.ln_2.weight\n",
      "gpt_neo/transformer.h.20.ln_2.bias\n",
      "gpt_neo/154947\n",
      "gpt_neo/transformer.h.13.ln_2.weight\n",
      "gpt_neo/transformer.h.5.ln_2.weight\n",
      "gpt_neo/transformer.h.17.ln_2.weight\n",
      "gpt_neo/transformer.h.19.ln_1.weight\n",
      "gpt_neo/transformer.h.15.attn.attention.out_proj.bias\n",
      "gpt_neo/transformer.h.1.ln_1.weight\n",
      "gpt_neo/154945\n",
      "gpt_neo/139000\n",
      "gpt_neo/transformer.h.2.ln_2.weight\n",
      "gpt_neo/138985\n",
      "gpt_neo/150377\n",
      "gpt_neo/136721\n",
      "gpt_neo/159487\n",
      "gpt_neo/157211\n",
      "gpt_neo/transformer.h.21.ln_1.weight\n",
      "gpt_neo/transformer.h.14.ln_1.bias\n",
      "gpt_neo/transformer.h.8.ln_2.bias\n",
      "gpt_neo/148099\n",
      "gpt_neo/150375\n",
      "gpt_neo/transformer.h.18.attn.attention.bias\n",
      "gpt_neo/141278\n",
      "gpt_neo/145822\n",
      "gpt_neo/139001\n",
      "gpt_neo/157223\n",
      "gpt_neo/transformer.h.7.ln_1.weight\n",
      "gpt_neo/transformer.h.5.ln_1.bias\n",
      "gpt_neo/152658\n",
      "gpt_neo/transformer.h.11.ln_1.weight\n",
      "gpt_neo/transformer.h.16.mlp.c_fc.bias\n",
      "gpt_neo/transformer.h.6.ln_2.weight\n",
      "gpt_neo/143543\n",
      "gpt_neo/transformer.h.1.ln_2.bias\n",
      "gpt_neo/transformer.h.15.mlp.c_fc.bias\n",
      "gpt_neo/transformer.h.20.mlp.c_fc.bias\n",
      "gpt_neo/136723\n",
      "gpt_neo/transformer.h.12.ln_2.bias\n",
      "gpt_neo/150378\n",
      "gpt_neo/157227\n",
      "gpt_neo/161767\n",
      "gpt_neo/143545\n",
      "gpt_neo/transformer.h.18.mlp.c_fc.bias\n",
      "gpt_neo/148100\n",
      "gpt_neo/152656\n",
      "gpt_neo/154949\n",
      "gpt_neo/transformer.h.16.attn.attention.bias\n",
      "gpt_neo/148112\n",
      "gpt_neo/154932\n",
      "gpt_neo/transformer.h.6.attn.attention.bias\n",
      "gpt_neo/141279\n",
      "gpt_neo/transformer.h.15.ln_2.bias\n",
      "gpt_neo/transformer.h.13.mlp.c_fc.bias\n",
      "gpt_neo/159492\n",
      "gpt_neo/transformer.h.21.ln_1.bias\n",
      "gpt_neo/143557\n",
      "gpt_neo/transformer.h.20.attn.attention.bias\n",
      "gpt_neo/138988\n",
      "gpt_neo/transformer.h.10.ln_1.bias\n",
      "gpt_neo/138987\n",
      "gpt_neo/transformer.h.17.ln_1.weight\n",
      "gpt_neo/150376\n",
      "gpt_neo/transformer.ln_f.weight\n",
      "gpt_neo/159503\n",
      "gpt_neo/transformer.h.4.mlp.c_proj.bias\n",
      "gpt_neo/transformer.h.7.ln_1.bias\n",
      "gpt_neo/transformer.h.0.ln_2.weight\n",
      "gpt_neo/transformer.h.1.ln_1.bias\n",
      "gpt_neo/transformer.h.7.ln_2.bias\n",
      "gpt_neo/157209\n",
      "gpt_neo/136711\n",
      "gpt_neo/141265\n",
      "gpt_neo/141266\n",
      "gpt_neo/157212\n",
      "gpt_neo/transformer.h.17.ln_2.bias\n",
      "gpt_neo/transformer.h.2.mlp.c_proj.bias\n",
      "gpt_neo/transformer.h.21.ln_2.bias\n",
      "gpt_neo/159500\n",
      "gpt_neo/154948\n",
      "gpt_neo/transformer.h.21.mlp.c_proj.bias\n",
      "gpt_neo/transformer.h.19.attn.attention.out_proj.bias\n",
      "gpt_neo/159490\n",
      "gpt_neo/143541\n",
      "gpt_neo/141277\n",
      "gpt_neo/141281\n",
      "gpt_neo/145823\n",
      "gpt_neo/161783\n",
      "gpt_neo/152653\n",
      "gpt_neo/transformer.h.10.mlp.c_fc.bias\n",
      "gpt_neo/transformer.h.0.mlp.c_fc.bias\n",
      "gpt_neo/transformer.h.20.attn.attention.out_proj.bias\n",
      "gpt_neo/164046\n",
      "gpt_neo/transformer.h.13.ln_1.bias\n",
      "gpt_neo/transformer.h.5.mlp.c_proj.bias\n",
      "gpt_neo/transformer.h.7.ln_2.weight\n",
      "gpt_neo/154934\n",
      "gpt_neo/150388\n",
      "gpt_neo/transformer.h.21.ln_2.weight\n",
      "gpt_neo/145836\n",
      "gpt_neo/transformer.h.3.ln_1.bias\n",
      "gpt_neo/transformer.h.23.ln_1.weight\n",
      "gpt_neo/148097\n",
      "gpt_neo/145834\n",
      "gpt_neo/138999\n",
      "gpt_neo/transformer.h.10.ln_2.weight\n",
      "gpt_neo/transformer.h.6.mlp.c_proj.bias\n",
      "gpt_neo/transformer.h.8.ln_1.weight\n",
      "gpt_neo/transformer.h.6.ln_1.bias\n",
      "gpt_neo/transformer.h.7.attn.attention.out_proj.bias\n",
      "gpt_neo/145824\n",
      "gpt_neo/150390\n",
      "gpt_neo/transformer.h.3.mlp.c_fc.bias\n",
      "gpt_neo/transformer.h.22.ln_2.weight\n",
      "gpt_neo/transformer.h.14.ln_2.weight\n",
      "gpt_neo/159491\n",
      "gpt_neo/157224\n",
      "gpt_neo/transformer.h.23.attn.attention.out_proj.bias\n",
      "gpt_neo/transformer.h.0.ln_1.weight\n",
      "gpt_neo/139002\n",
      "gpt_neo/139003\n",
      "gpt_neo/154933\n",
      "gpt_neo/145819\n",
      "gpt_neo/transformer.h.15.ln_2.weight\n",
      "gpt_neo/transformer.h.17.ln_1.bias\n",
      "gpt_neo/transformer.h.7.mlp.c_proj.bias\n",
      "gpt_neo/transformer.h.12.mlp.c_fc.bias\n",
      "gpt_neo/150392\n",
      "gpt_neo/141280\n",
      "gpt_neo/138986\n",
      "gpt_neo/transformer.h.22.mlp.c_fc.bias\n",
      "gpt_neo/145835\n",
      "gpt_neo/transformer.h.12.attn.attention.out_proj.bias\n",
      "gpt_neo/transformer.h.2.ln_1.weight\n",
      "gpt_neo/transformer.h.23.mlp.c_fc.bias\n",
      "gpt_neo/161780\n",
      "gpt_neo/transformer.h.13.mlp.c_proj.bias\n",
      "gpt_neo/152655\n",
      "gpt_neo/transformer.ln_f.bias\n",
      "gpt_neo/transformer.h.2.attn.attention.bias\n",
      "gpt_neo/transformer.h.9.attn.attention.out_proj.bias\n",
      "gpt_neo/157225\n",
      "gpt_neo/transformer.h.9.mlp.c_fc.bias\n",
      "gpt_neo/transformer.h.9.ln_1.bias\n",
      "gpt_neo/148113\n",
      "gpt_neo/transformer.h.5.mlp.c_fc.bias\n",
      "gpt_neo/transformer.h.22.ln_2.bias\n",
      "gpt_neo/transformer.h.14.ln_1.weight\n",
      "gpt_neo/transformer.h.0.attn.attention.out_proj.bias\n",
      "gpt_neo/141264\n",
      "gpt_neo/transformer.h.16.ln_2.bias\n",
      "gpt_neo/transformer.h.3.ln_1.weight\n",
      "gpt_neo/152668\n",
      "gpt_neo/164045\n",
      "gpt_neo/transformer.h.4.ln_2.bias\n",
      "gpt_neo/150379\n",
      "gpt_neo/transformer.h.0.ln_1.bias\n",
      "gpt_neo/157222\n",
      "gpt_neo/transformer.h.12.mlp.c_proj.bias\n",
      "gpt_neo/transformer.h.6.ln_2.bias\n",
      "gpt_neo/152667\n",
      "gpt_neo/143559\n",
      "gpt_neo/164043\n",
      "gpt_neo/transformer.h.21.attn.attention.out_proj.bias\n",
      "gpt_neo/transformer.h.12.attn.attention.bias\n",
      "gpt_neo/transformer.h.19.ln_2.weight\n",
      "gpt_neo/transformer.h.1.mlp.c_proj.bias\n",
      "gpt_neo/145820\n",
      "gpt_neo/transformer.h.12.ln_1.weight\n",
      "gpt_neo/143544\n",
      "gpt_neo/transformer.h.15.ln_1.bias\n",
      "gpt_neo/transformer.h.7.mlp.c_fc.bias\n",
      "gpt_neo/136720\n",
      "gpt_neo/159489\n",
      "gpt_neo/148115\n",
      "gpt_neo/138998\n",
      "gpt_neo/159502\n",
      "gpt_neo/transformer.h.9.ln_2.bias\n",
      "gpt_neo/transformer.h.19.ln_2.bias\n",
      "gpt_neo/transformer.h.6.mlp.c_fc.bias\n",
      "gpt_neo/transformer.h.23.mlp.c_proj.bias\n",
      "gpt_neo/transformer.h.0.ln_2.bias\n",
      "gpt_neo/145837\n",
      "gpt_neo/transformer.h.18.mlp.c_proj.bias\n",
      "gpt_neo/transformer.h.11.ln_1.bias\n",
      "gpt_neo/transformer.h.10.ln_2.bias\n",
      "gpt_neo/transformer.h.17.mlp.c_proj.bias\n",
      "gpt_neo/transformer.h.22.ln_1.weight\n",
      "gpt_neo/157210\n",
      "gpt_neo/transformer.h.0.mlp.c_proj.bias\n",
      "gpt_neo/transformer.h.18.ln_1.bias\n",
      "gpt_neo/transformer.h.0.attn.attention.bias\n",
      "gpt_neo/143546\n",
      "gpt_neo/transformer.h.4.ln_2.weight\n",
      "gpt_neo/157213\n",
      "gpt_neo/transformer.h.8.mlp.c_proj.bias\n",
      "gpt_neo/152671\n",
      "gpt_neo/152669\n",
      "gpt_neo/148114\n",
      "gpt_neo/138990\n",
      "gpt_neo/transformer.h.8.mlp.c_fc.bias\n",
      "gpt_neo/transformer.h.18.ln_2.weight\n",
      "gpt_neo/transformer.h.20.ln_2.weight\n",
      "gpt_neo/transformer.h.10.mlp.c_proj.bias\n",
      "gpt_neo/transformer.h.3.attn.attention.out_proj.bias\n",
      "gpt_neo/transformer.h.11.mlp.c_fc.bias\n",
      "gpt_neo/transformer.h.22.attn.attention.bias\n"
     ]
    }
   ],
   "source": [
    "!tar -xvzf gpt_neo.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a35a73f",
   "metadata": {},
   "source": [
    "## CUDAExecutionProvider + CPUExecutionProvider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13c9762d",
   "metadata": {},
   "outputs": [],
   "source": [
    "providers = [\"CUDAExecutionProvider\", \"CPUExecutionProvider\"]\n",
    "sess = rt.InferenceSession(str(model_pth), opt, providers=providers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "844fdc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding 1000 sentences took 313s at 3 sentences/s.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for _ in range(len(sents)):\n",
    "    model_input = tokenizer.encode_plus(\"hello my friends!\")\n",
    "    model_input = {name : np.atleast_2d(value) for name, value in model_input.items()}\n",
    "    _ = sess.run(None, model_input)\n",
    "\n",
    "duration = int(time.time() - start)\n",
    "speed = int(MAX_SENTENCES / duration)\n",
    "print(f\"encoding {MAX_SENTENCES} sentences took {duration}s at {speed} sentences/s.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
