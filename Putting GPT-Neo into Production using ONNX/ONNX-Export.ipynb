{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae351fa9",
   "metadata": {},
   "source": [
    "# Putting Transformers into Production with ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70a6aa0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: transformers 4.4.2\n",
      "Uninstalling transformers-4.4.2:\n",
      "  Successfully uninstalled transformers-4.4.2\n",
      "Collecting git+https://github.com/huggingface/transformers.git\n",
      "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-6wtmcy5l\n",
      "  Running command git clone -q https://github.com/huggingface/transformers.git /tmp/pip-req-build-6wtmcy5l\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from transformers==4.5.0.dev0) (20.9)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.5.0.dev0) (2021.3.17)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==4.5.0.dev0) (2.25.1)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.8/dist-packages (from transformers==4.5.0.dev0) (0.0.43)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.5.0.dev0) (1.19.5)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.5.0.dev0) (0.10.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers==4.5.0.dev0) (4.59.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.5.0.dev0) (3.0.12)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->transformers==4.5.0.dev0) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.5.0.dev0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.5.0.dev0) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.5.0.dev0) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.5.0.dev0) (4.0.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==4.5.0.dev0) (1.15.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==4.5.0.dev0) (1.0.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==4.5.0.dev0) (7.1.2)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.5.0.dev0-py3-none-any.whl size=2059073 sha256=c36c407572a03ce3ad49a12ec81f563ed7b9b622d9cbb602c0aa8d0ceae33886\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-6329cr5a/wheels/05/0a/97/64ae47c27ba95fae2cb5838e7b4b7247a34d4a8ba5f7092de2\n",
      "Successfully built transformers\n",
      "Installing collected packages: transformers\n",
      "Successfully installed transformers-4.5.0.dev0\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence-transformers-1.0.4.tar.gz (74 kB)\n",
      "\u001b[K     |████████████████████████████████| 74 kB 5.4 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (1.1.0)\n",
      "Collecting IProgress\n",
      "  Downloading IProgress-0.4-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from IProgress) (1.15.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (4.5.0.dev0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (4.59.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (1.8.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (1.19.5)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (0.24.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (1.6.2)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.5.zip (1.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 18.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.95-cp38-cp38-manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 41.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2021.3.17)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (20.9)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.12)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2.25.1)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.10.1)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.0.43)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk->sentence-transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk->sentence-transformers) (1.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (4.0.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sentence-transformers) (2.1.0)\n",
      "Building wheels for collected packages: sentence-transformers, nltk\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-1.0.4-py3-none-any.whl size=114306 sha256=a21830b65e0a976727ea71b04858fb2f6e066ff169fe09e845655adfbab9a114\n",
      "  Stored in directory: /root/.cache/pip/wheels/28/cb/ae/360fe121dc748add4fabecd46e78c31d1ea2402d341f97e2dc\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nltk: filename=nltk-3.5-py3-none-any.whl size=1434676 sha256=e9814e064fe5957ba6e05f3752bdee43675d0da88bd9fa8d021b374634315385\n",
      "  Stored in directory: /root/.cache/pip/wheels/ff/d5/7b/f1fb4e1e1603b2f01c2424dd60fbcc50c12ef918bafc44b155\n",
      "Successfully built sentence-transformers nltk\n",
      "Installing collected packages: sentencepiece, nltk, sentence-transformers, IProgress\n",
      "Successfully installed IProgress-0.4 nltk-3.5 sentence-transformers-1.0.4 sentencepiece-0.1.95\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y transformers\n",
    "!pip install -U git+https://github.com/huggingface/transformers.git\n",
    "!pip install sentence-transformers termcolor IProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25a1c532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX Runtime Execution Providers: \n",
      "['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n"
     ]
    }
   ],
   "source": [
    "!echo \"ONNX Runtime Execution Providers: \" && python -c \"import onnxruntime as ort; print(ort.get_available_providers())\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9ef498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export ORT_TENSORRT_MAX_BATCH_SIZE=10\n",
    "!export ORT_TENSORRT_MAX_WORKSPACE_SIZE=4294967296\n",
    "!export ORT_TENSORRT_MAX_PARTITION_ITERATIONS=20\n",
    "!export ORT_TENSORRT_MIN_SUBGRAPH_SIZE=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28e4cb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1\n",
      "1.7.1\n",
      "4.5.0.dev0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import onnx\n",
    "import onnxruntime as rt\n",
    "import multiprocessing\n",
    "import transformers\n",
    "\n",
    "from termcolor import colored\n",
    "from transformers import convert_graph_to_onnx\n",
    "from pathlib import Path\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from onnxruntime_customops import get_library_path\n",
    "\n",
    "print(onnx.__version__)\n",
    "print(rt.__version__)\n",
    "print(transformers.__version__)\n",
    "\n",
    "span = \"Hello my friends!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8c0f99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ONNX_PROVIDERS = [\"CUDAExecutionProvider\", \"CPUExecutionProvider\",]\n",
    "\n",
    "opt = rt.SessionOptions()\n",
    "opt.register_custom_ops_library(get_library_path())\n",
    "opt.graph_optimization_level = rt.GraphOptimizationLevel.ORT_ENABLE_EXTENDED\n",
    "opt.log_severity_level = 4\n",
    "opt.intra_op_num_threads = multiprocessing.cpu_count()\n",
    "opt.execution_mode = rt.ExecutionMode.ORT_SEQUENTIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "619db4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mGPU available True\u001b[0m\n",
      "\u001b[32mGPU Name: Tesla V100-SXM2-32GB\u001b[0m\n",
      "\u001b[32mGPU Count: 1\u001b[0m\n",
      "\u001b[32mCORE Count: 48\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(colored(f\"GPU available {torch.cuda.is_available()}\", \"green\"))\n",
    "print(colored(f\"GPU Name: {torch.cuda.get_device_name(0)}\", \"green\"))\n",
    "print(colored(f\"GPU Count: {torch.cuda.device_count()}\", \"green\"))\n",
    "print(colored(f\"CORE Count: {multiprocessing.cpu_count()}\", \"green\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e55f90e",
   "metadata": {},
   "source": [
    "## 1. Simple Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbb40c42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d3bfdbef132431497791d9fb3c97bac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/461 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b9a1a149c3b4b13bfe67c61a52a530f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1496094d1b7b4e88bdf8cc4d5fd62031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a26ff85f726e43559e72d41974e5fdff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40d7ee888afa4c259d124c89b18cd301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX opset version set to: 12\n",
      "Loading pipeline (model: sentence-transformers/bert-base-nli-stsb-mean-tokens, tokenizer: sentence-transformers/bert-base-nli-stsb-mean-tokens)\n",
      "Creating folder encoder\n",
      "Using framework PyTorch: 1.8.1+cu102\n",
      "Found input input_ids with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found input token_type_ids with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found input attention_mask with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_0 with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_1 with shape: {0: 'batch'}\n",
      "Ensuring inputs are in correct order\n",
      "position_ids is not present in the generated input list.\n",
      "Generated inputs order: ['input_ids', 'attention_mask', 'token_type_ids']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py:1789: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert all(\n"
     ]
    }
   ],
   "source": [
    "model_name = \"sentence-transformers/bert-base-nli-stsb-mean-tokens\"\n",
    "pipeline_name = \"feature-extraction\"\n",
    "model_pth = Path(f\"encoder/bert-base-nli-stsb-mean-tokens.onnx\")\n",
    "\n",
    "nlp = transformers.pipeline(pipeline_name, model=model_name, tokenizer=model_name, device=0)\n",
    "tokenizer = nlp.tokenizer\n",
    "\n",
    "if not model_pth.exists():\n",
    "    convert_graph_to_onnx.convert(\n",
    "        framework=\"pt\",\n",
    "        model=model_name,\n",
    "        output=model_pth,\n",
    "        opset=12,\n",
    "        tokenizer=model_name,\n",
    "        use_external_format= False,\n",
    "        pipeline_name= pipeline_name,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3139f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c11afba306f4797aa1952366c0c18d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/405M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_raw = SentenceTransformer(\"bert-base-nli-stsb-mean-tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3bcd564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.86 ms ± 914 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "nlp(span)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11b08f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.4 ms ± 623 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "model_raw.encode(span)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16ba336b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = rt.InferenceSession(str(model_pth), opt, providers=ONNX_PROVIDERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8672c681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.28 ms ± 164 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "model_input = tokenizer.encode_plus(span)\n",
    "model_input = {name : np.atleast_2d(value) for name, value in model_input.items()}\n",
    "onnx_result = sess.run(None, model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1319e6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 6, 768)\n",
      "(1, 768)\n"
     ]
    }
   ],
   "source": [
    "model_input = tokenizer.encode_plus(span)\n",
    "model_input = {name : np.atleast_2d(value) for name, value in model_input.items()}\n",
    "onnx_result = sess.run(None, model_input)\n",
    "\n",
    "print(onnx_result[0].shape)\n",
    "print(onnx_result[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96944eb",
   "metadata": {},
   "source": [
    "## 2. Custom Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c499d2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found input input_ids with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found input token_type_ids with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found input attention_mask with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_0 with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_1 with shape: {0: 'batch'}\n",
      "Ensuring inputs are in correct order\n",
      "position_ids is not present in the generated input list.\n",
      "Generated inputs order: ['input_ids', 'attention_mask', 'token_type_ids']\n",
      "\n",
      "Inferred shapes for sentence-transformers/bert-base-nli-stsb-mean-tokens\n",
      "Input names: ['input_ids', 'token_type_ids', 'attention_mask']\n",
      "Output names: ['output_0', 'output_1']\n",
      "Dynamic Axes:\n",
      "{\n",
      "    \"attention_mask\": {\n",
      "        \"0\": \"batch\",\n",
      "        \"1\": \"sequence\"\n",
      "    },\n",
      "    \"input_ids\": {\n",
      "        \"0\": \"batch\",\n",
      "        \"1\": \"sequence\"\n",
      "    },\n",
      "    \"output_0\": {\n",
      "        \"0\": \"batch\",\n",
      "        \"1\": \"sequence\"\n",
      "    },\n",
      "    \"output_1\": {\n",
      "        \"0\": \"batch\"\n",
      "    },\n",
      "    \"token_type_ids\": {\n",
      "        \"0\": \"batch\",\n",
      "        \"1\": \"sequence\"\n",
      "    }\n",
      "}\n",
      "Tokens:{'input_ids': tensor([[ 101, 2023, 2003, 1037, 7099, 6434,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}\n",
      "Ordered input names: ['input_ids', 'attention_mask', 'token_type_ids']\n",
      "Arguments: (tensor([[ 101, 2023, 2003, 1037, 7099, 6434,  102]]), tensor([[1, 1, 1, 1, 1, 1, 1]]), tensor([[0, 0, 0, 0, 0, 0, 0]]))\n"
     ]
    }
   ],
   "source": [
    "def print_transformers_shape_inference(name_or_path: str):\n",
    "    \"\"\"Prints the transformers shape inference for onnx.\"\"\"\n",
    "    res = {}\n",
    "    \n",
    "    model_pipeline = transformers.FeatureExtractionPipeline(\n",
    "        model=transformers.AutoModel.from_pretrained(name_or_path),\n",
    "        tokenizer=transformers.AutoTokenizer.from_pretrained(\n",
    "            name_or_path, use_fast=True\n",
    "        ),\n",
    "        framework=\"pt\",\n",
    "        device=-1,\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        (\n",
    "            input_names,\n",
    "            output_names,\n",
    "            dynamic_axes,\n",
    "            tokens,\n",
    "        ) = convert_graph_to_onnx.infer_shapes(model_pipeline, \"pt\")\n",
    "        ordered_input_names, model_args = convert_graph_to_onnx.ensure_valid_input(\n",
    "            model_pipeline.model, tokens, input_names\n",
    "        )\n",
    "\n",
    "    res[\"input_names\"] = input_names\n",
    "    res[\"output_names\"] = output_names\n",
    "    res[\"dynamic_axes\"] = dynamic_axes\n",
    "    res[\"tokens\"] = tokens\n",
    "    res[\"exemplary_input\"] = model_args\n",
    "    \n",
    "    print()\n",
    "    print(f\"Inferred shapes for {name_or_path}\")\n",
    "    print(f\"Input names: {input_names}\")\n",
    "    print(f\"Output names: {output_names}\")\n",
    "    print(f\"Dynamic Axes:\\n{json.dumps(dynamic_axes,sort_keys=True, indent=4)}\")\n",
    "    print(f\"Tokens:{tokens}\")\n",
    "    print(f\"Ordered input names: {ordered_input_names}\")\n",
    "    print(f\"Arguments: {model_args}\")\n",
    "    \n",
    "    return res\n",
    "\n",
    "model_args = print_transformers_shape_inference(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f851401e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_names': ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       " 'output_names': ['output_0', 'output_1'],\n",
       " 'dynamic_axes': {'input_ids': {0: 'batch', 1: 'sequence'},\n",
       "  'token_type_ids': {0: 'batch', 1: 'sequence'},\n",
       "  'attention_mask': {0: 'batch', 1: 'sequence'},\n",
       "  'output_0': {0: 'batch', 1: 'sequence'},\n",
       "  'output_1': {0: 'batch'}},\n",
       " 'tokens': {'input_ids': tensor([[ 101, 2023, 2003, 1037, 7099, 6434,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])},\n",
       " 'exemplary_input': (tensor([[ 101, 2023, 2003, 1037, 7099, 6434,  102]]),\n",
       "  tensor([[1, 1, 1, 1, 1, 1, 1]]),\n",
       "  tensor([[0, 0, 0, 0, 0, 0, 0]]))}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf214181",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceTransformer(transformers.BertModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        # Naming alias for ONNX output specification\n",
    "        # Makes it easier to identify the layer\n",
    "        self.sentence_embedding = torch.nn.Identity()\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids, attention_mask):\n",
    "        # Get the token embeddings from the base model\n",
    "        token_embeddings = super().forward(\n",
    "            input_ids, \n",
    "            attention_mask=attention_mask, \n",
    "            token_type_ids=token_type_ids\n",
    "        )[0]\n",
    "        # Stack the pooling layer on top of it\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size())\n",
    "        sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "        return self.sentence_embedding(sum_embeddings / sum_mask)\n",
    "\n",
    "# Create the new model based on the config of the original pipeline\n",
    "model = SentenceTransformer(config=nlp.model.config).from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5873514",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(\n",
    "    model_raw.encode(span),\n",
    "    model(**tokenizer(span, return_tensors=\"pt\")).squeeze().detach().numpy(),\n",
    "    atol=1e-6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d32e4dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model_args[\"dynamic_axes\"][\"output_0\"] # Delete unused output\n",
    "del model_args[\"dynamic_axes\"][\"output_1\"] # Delete unused output\n",
    "model_args[\"dynamic_axes\"][\"sentence_embedding\"] = {0: \"batch\"}\n",
    "\n",
    "model_args[\"output_names\"] = [\"sentence_embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61bc461f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_names': ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       " 'output_names': ['sentence_embedding'],\n",
       " 'dynamic_axes': {'input_ids': {0: 'batch', 1: 'sequence'},\n",
       "  'token_type_ids': {0: 'batch', 1: 'sequence'},\n",
       "  'attention_mask': {0: 'batch', 1: 'sequence'},\n",
       "  'sentence_embedding': {0: 'batch'}},\n",
       " 'tokens': {'input_ids': tensor([[ 101, 2023, 2003, 1037, 7099, 6434,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])},\n",
       " 'exemplary_input': (tensor([[ 101, 2023, 2003, 1037, 7099, 6434,  102]]),\n",
       "  tensor([[1, 1, 1, 1, 1, 1, 1]]),\n",
       "  tensor([[0, 0, 0, 0, 0, 0, 0]]))}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1776298e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outdir = Path(\"encoder\")\n",
    "output = outdir / \"bert-base-nli-stsb-mean-tokens-pooling.onnx\"\n",
    "outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    model_args[\"exemplary_input\"],\n",
    "    f=output.as_posix(),\n",
    "    input_names=model_args[\"input_names\"],\n",
    "    output_names=model_args[\"output_names\"],\n",
    "    dynamic_axes=model_args[\"dynamic_axes\"],\n",
    "    do_constant_folding=True,\n",
    "    use_external_data_format=False,\n",
    "    enable_onnx_checker=True,\n",
    "    opset_version=12,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8193dd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = rt.InferenceSession(str(output), opt, providers=ONNX_PROVIDERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8a9c096",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = tokenizer.encode_plus(span)\n",
    "model_input = {name : np.atleast_2d(value) for name, value in model_input.items()}\n",
    "onnx_result = sess.run(None, model_input)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55c9b711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 768)\n"
     ]
    }
   ],
   "source": [
    "print(onnx_result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29513bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.38 ms ± 86.4 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "model_input = tokenizer.encode_plus(span)\n",
    "model_input = {name : np.atleast_2d(value) for name, value in model_input.items()}\n",
    "onnx_result = sess.run(None, model_input)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3306094e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(\n",
    "    model_raw.encode(span),\n",
    "    onnx_result,\n",
    "    atol=1e-6,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236ff77b",
   "metadata": {},
   "source": [
    "## 3. Export with ORT Custom-OPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0631422",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-05 19:07:36--  https://storage.googleapis.com/tfhub-modules/google/universal-sentence-encoder-large/5.tar.gz\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 2a00:1450:4001:80f::2010, 2a00:1450:4001:827::2010, 2a00:1450:4001:828::2010, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|2a00:1450:4001:80f::2010|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 548921135 (523M) [application/x-tar]\n",
      "Saving to: ‘5.tar.gz’\n",
      "\n",
      "5.tar.gz            100%[===================>] 523.49M  67.7MB/s    in 8.3s    \n",
      "\n",
      "2021-04-05 19:07:44 (62.8 MB/s) - ‘5.tar.gz’ saved [548921135/548921135]\n",
      "\n",
      "./\n",
      "./assets/\n",
      "./variables/\n",
      "./variables/variables.index\n",
      "./variables/variables.data-00000-of-00001\n",
      "./saved_model.pb\n",
      "2021-04-05 19:07:51.421900: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "/usr/lib/python3.8/runpy.py:127: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2021-04-05 19:07:52,980 - WARNING - tensorflow_text not installed. Model will fail to load if tensorflow_text ops are used.\n",
      "2021-04-05 19:07:52.981167: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-04-05 19:07:52.982154: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-04-05 19:07:53.038370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:b3:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2021-04-05 19:07:53.038406: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-04-05 19:07:53.041880: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-04-05 19:07:53.041959: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-04-05 19:07:53.043181: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-04-05 19:07:53.043496: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-04-05 19:07:53.043803: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib.real:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2021-04-05 19:07:53.044682: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-04-05 19:07:53.044862: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-04-05 19:07:53.044877: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-04-05 19:07:53.045230: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-04-05 19:07:53.049518: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-04-05 19:07:53.049581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-04-05 19:07:53.049597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      \n",
      "2021-04-05 19:08:04.467340: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-04-05 19:08:04.901976: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2400000000 Hz\n",
      "2021-04-05 19:08:06,468 - INFO - Signatures found in model: [serving_default].\n",
      "2021-04-05 19:08:06,468 - WARNING - '--signature_def' not specified, using first signature: serving_default\n",
      "2021-04-05 19:08:06,472 - INFO - Output names: ['outputs']\n",
      "2021-04-05 19:08:06.707179: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2021-04-05 19:08:06.707384: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
      "2021-04-05 19:08:06.707808: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-04-05 19:08:06.710590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:b3:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2021-04-05 19:08:06.710666: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-04-05 19:08:06.710818: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-04-05 19:08:06.710835: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-04-05 19:08:06.710849: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-04-05 19:08:06.710860: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-04-05 19:08:06.710965: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib.real:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2021-04-05 19:08:06.710979: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-04-05 19:08:06.710990: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-04-05 19:08:06.710998: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-04-05 19:08:06.887689: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-04-05 19:08:06.887731: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-04-05 19:08:06.887740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-04-05 19:08:07.490531: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:928] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: Graph size after: 10152 nodes (7149), 10272 edges (7269), time = 364.422ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 10.543ms.\n",
      "\n",
      "2021-04-05 19:08:26.757705: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-04-05 19:08:26.757790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-04-05 19:08:26.757799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      \n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tf2onnx/tf_loader.py:557: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2021-04-05 19:08:30,069 - WARNING - From /usr/local/lib/python3.8/dist-packages/tf2onnx/tf_loader.py:557: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2021-04-05 19:08:30.811281: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2021-04-05 19:08:30.811487: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
      "2021-04-05 19:08:30.811977: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-04-05 19:08:30.817356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:b3:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2021-04-05 19:08:30.817470: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-04-05 19:08:30.817611: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-04-05 19:08:30.817644: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-04-05 19:08:30.817677: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-04-05 19:08:30.817705: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-04-05 19:08:30.817896: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib.real:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2021-04-05 19:08:30.817933: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-04-05 19:08:30.817959: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-04-05 19:08:30.817975: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-04-05 19:08:30.818023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-04-05 19:08:30.818040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-04-05 19:08:30.818056: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-04-05 19:08:36.086937: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:928] Optimization results for grappler item: graph_to_optimize\n",
      "  constant_folding: Graph size after: 1181 nodes (-8701), 1451 edges (-8701), time = 2815.64111ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 20.013ms.\n",
      "  constant_folding: Graph size after: 1181 nodes (0), 1451 edges (0), time = 794.705ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 7.345ms.\n",
      "\n",
      "2021-04-05 19:08:39,567 - INFO - Using tensorflow=2.4.1, onnx=1.8.1, tf2onnx=1.8.4/cd55bf\n",
      "2021-04-05 19:08:39,567 - INFO - Using opset <onnx, 12>\n",
      "2021-04-05 19:08:39,580 - WARNING - Cannot infer shape for StatefulPartitionedCall/text_preprocessor_1/hash_table_Lookup/hash_table_Lookup/LookupTableFindV2: StatefulPartitionedCall/text_preprocessor_1/hash_table_Lookup/hash_table_Lookup/LookupTableFindV2:0\n",
      "2021-04-05 19:08:39,580 - WARNING - Cannot infer shape for StatefulPartitionedCall/text_preprocessor_1/hash_table_Lookup/NotEqual: StatefulPartitionedCall/text_preprocessor_1/hash_table_Lookup/NotEqual:0\n",
      "2021-04-05 19:08:39,580 - WARNING - Cannot infer shape for StatefulPartitionedCall/text_preprocessor_1/hash_table_Lookup/SelectV2: StatefulPartitionedCall/text_preprocessor_1/hash_table_Lookup/SelectV2:0\n",
      "2021-04-05 19:08:39,580 - WARNING - Cannot infer shape for StatefulPartitionedCall/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/Reshape_1: StatefulPartitionedCall/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/Reshape_1:0\n",
      "2021-04-05 19:08:55,083 - INFO - Computed 0 values for constant folding\n",
      "2021-04-05 19:09:39,071 - INFO - Optimizing ONNX model\n",
      "2021-04-05 19:09:49,934 - INFO - After optimization: Cast -117 (223->106), Concat -5 (46->41), Const -601 (819->218), ConstantOfShape -22 (27->5), Div -1 (10->9), Equal -1 (3->2), Expand -5 (12->7), Identity -37 (37->0), OneHot -1 (4->3), Reshape -5 (42->37), ScatterND -5 (25->20), Shape -6 (45->39), Slice -6 (69->63), Split -1 (2->1), Squeeze -85 (122->37), Sub -13 (29->16), Transpose -6 (32->26), Unsqueeze -102 (114->12)\n",
      "2021-04-05 19:09:50,646 - INFO - \n",
      "2021-04-05 19:09:50,646 - INFO - Successfully converted TensorFlow model universal-sentence-encoder-5 to ONNX\n",
      "2021-04-05 19:09:50,646 - INFO - Model inputs: ['inputs:0']\n",
      "2021-04-05 19:09:50,646 - INFO - Model outputs: ['outputs']\n",
      "2021-04-05 19:09:50,646 - INFO - ONNX model is saved at encoder/universal-sentence-encoder-5.onnx\n"
     ]
    }
   ],
   "source": [
    "!bash use5.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e6f8b56c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.34950260e-03,  2.62679085e-02, -1.07614197e-01,\n",
       "        -1.99584328e-02,  4.63480456e-03,  8.49447493e-03,\n",
       "         2.51034517e-02, -2.90801805e-02,  2.21730396e-02,\n",
       "        -1.00490581e-02,  9.49494448e-03, -3.26025523e-02,\n",
       "        -1.32153835e-02, -1.85077582e-02, -6.01154454e-02,\n",
       "         1.85450036e-02,  1.17757544e-02, -5.08113876e-02,\n",
       "        -4.71790917e-02,  2.50959080e-02,  3.06968554e-03,\n",
       "        -1.85236465e-02, -6.13590591e-02, -5.80388913e-03,\n",
       "         7.58706704e-02,  2.40540244e-02, -1.60349458e-02,\n",
       "        -7.69246221e-02,  2.79430393e-02,  2.23552212e-02,\n",
       "         2.06381734e-02, -2.15326883e-02, -4.23278026e-02,\n",
       "        -9.65398476e-02,  1.82510875e-02,  1.71697009e-02,\n",
       "         1.02297226e-02, -7.17197824e-03,  5.71188442e-02,\n",
       "        -6.49892986e-02,  5.56984451e-03, -2.10656691e-02,\n",
       "        -1.31348064e-02,  4.22912091e-02,  5.61305657e-02,\n",
       "        -9.58824530e-03, -4.63117845e-02, -6.88697724e-03,\n",
       "         2.34971046e-02, -9.47435200e-02, -5.15654758e-02,\n",
       "         9.63695440e-03, -6.33907244e-02,  2.42003202e-02,\n",
       "        -1.88094899e-02,  1.70212984e-02,  2.26583220e-02,\n",
       "         2.27678157e-02,  2.07756665e-02,  5.38659841e-02,\n",
       "        -2.39527971e-02, -2.85012331e-02, -5.04828468e-02,\n",
       "        -1.39614437e-02,  3.86392660e-02, -1.02858655e-02,\n",
       "         6.10126667e-02, -1.72149502e-02, -7.48697249e-03,\n",
       "         2.95636375e-02, -9.34059396e-02, -5.79344891e-02,\n",
       "         2.68297158e-02,  5.51378075e-03, -2.71401368e-02,\n",
       "        -3.60978208e-02, -5.17584197e-02, -6.56663626e-02,\n",
       "         4.06431267e-03,  1.80068873e-02,  4.04406674e-02,\n",
       "        -8.29258282e-03,  5.82105033e-02,  6.32137880e-02,\n",
       "        -4.32405658e-02,  3.38003635e-02,  2.28608120e-02,\n",
       "         1.26200086e-02, -2.64886431e-02, -1.05063440e-02,\n",
       "        -3.19428183e-02, -5.03872149e-02, -5.93477413e-02,\n",
       "         5.10655604e-02, -1.95955373e-02,  6.62969723e-02,\n",
       "        -2.77432669e-02, -5.43903522e-02,  7.49687925e-02,\n",
       "         3.04412339e-02, -9.41000320e-03, -7.52661079e-02,\n",
       "        -2.71650273e-02,  2.98907259e-03,  3.05723809e-02,\n",
       "        -4.56927419e-02, -3.24856155e-02, -1.96882170e-02,\n",
       "        -2.37415973e-02,  4.26183231e-02, -1.59488786e-02,\n",
       "         7.34138563e-02,  5.94476499e-02,  4.82335873e-02,\n",
       "         7.36554265e-02,  6.26596138e-02, -6.99741170e-02,\n",
       "         6.97919354e-03, -2.14010458e-02,  3.60510522e-03,\n",
       "        -1.59062762e-02,  9.82463881e-02, -1.30377719e-02,\n",
       "         5.61588220e-02, -1.75792929e-02,  2.67657489e-02,\n",
       "         9.00386926e-03,  3.80627066e-02,  5.03537767e-02,\n",
       "         3.16937082e-02,  2.61131488e-03,  1.53070660e-02,\n",
       "        -2.18255147e-02, -4.76479009e-02,  4.42660041e-02,\n",
       "         4.51572500e-02, -7.31758922e-02,  3.63871013e-03,\n",
       "        -2.35247295e-02, -4.78173383e-02,  2.89135613e-02,\n",
       "         2.19139755e-02, -2.68542990e-02, -9.50001925e-03,\n",
       "        -2.98873056e-02,  3.03402618e-02,  3.65997404e-02,\n",
       "        -8.47391486e-02, -7.19393790e-02, -5.69096468e-02,\n",
       "        -1.94923636e-02,  3.50516252e-02, -7.35703930e-02,\n",
       "        -1.50152445e-02,  1.32531412e-02,  4.34035994e-02,\n",
       "         2.28693895e-02,  1.09333411e-01, -3.01856287e-02,\n",
       "         1.63703430e-02,  5.69861419e-02,  3.68445702e-02,\n",
       "        -5.23335561e-02,  3.87071893e-02,  8.09570923e-02,\n",
       "        -4.27342020e-02,  3.34740318e-02, -4.78753969e-02,\n",
       "        -9.71523747e-02,  4.63802442e-02, -1.53294262e-02,\n",
       "         5.55579434e-04,  1.27636418e-01,  2.94152331e-02,\n",
       "        -2.25137956e-02,  8.54053348e-02, -1.56573895e-02,\n",
       "        -3.69908214e-02, -1.53271668e-02,  1.20140631e-02,\n",
       "         1.44060897e-02, -6.04027100e-02,  7.80902483e-05,\n",
       "         2.05313955e-02, -5.29844277e-02,  1.42887095e-02,\n",
       "         1.63962692e-02, -2.82524731e-02,  3.43241729e-03,\n",
       "         2.42286343e-02, -7.95887187e-02, -7.43295439e-03,\n",
       "        -4.71370816e-02, -4.76471297e-02,  1.92485303e-02,\n",
       "         5.32077141e-02, -3.94886881e-02,  7.90629536e-02,\n",
       "         3.48995849e-02, -5.85446656e-02,  7.91579410e-02,\n",
       "        -1.53502887e-02, -2.02640463e-02,  5.44747971e-02,\n",
       "        -4.05339785e-02,  2.81227063e-02,  2.39893626e-02,\n",
       "        -3.76927704e-02,  3.35533842e-02,  3.94109748e-02,\n",
       "        -3.73369940e-02,  3.39173852e-03,  2.92090550e-02,\n",
       "         6.82903230e-02, -1.01189427e-01, -3.03348321e-02,\n",
       "        -5.26201911e-02,  1.81938661e-03, -8.59889295e-03,\n",
       "        -1.13857398e-02, -4.11110483e-02, -8.35731160e-03,\n",
       "         8.52906927e-02,  1.08548151e-02, -2.95703337e-02,\n",
       "         9.82744098e-02,  1.94543984e-03,  1.49142623e-01,\n",
       "         2.41265073e-03, -8.63349717e-03, -6.68094959e-03,\n",
       "         4.82560135e-02,  6.05571680e-02,  3.38010937e-02,\n",
       "        -1.93221960e-02,  8.31048936e-02, -2.92707495e-02,\n",
       "         2.73649544e-02, -2.59092208e-02, -1.18375774e-02,\n",
       "        -1.44742196e-02, -3.50696258e-02, -4.88082916e-02,\n",
       "         2.08367482e-02,  1.09679662e-01, -6.07078848e-03,\n",
       "         5.99154383e-02,  5.10559790e-03,  3.39025911e-03,\n",
       "         5.35145737e-02,  5.02272062e-02, -4.69761230e-02,\n",
       "        -2.77875774e-02, -5.08371415e-03, -1.47897273e-03,\n",
       "         6.04415052e-02,  9.29727405e-03, -2.64182389e-02,\n",
       "         2.53873728e-02,  4.59790556e-03, -4.81706932e-02,\n",
       "        -1.13514159e-02, -2.13064924e-02,  6.85286894e-03,\n",
       "         5.50200082e-02,  2.24897661e-03, -2.09649634e-02,\n",
       "        -5.76630607e-03,  1.12772118e-02, -1.21629704e-02,\n",
       "         6.29918426e-02,  2.61077881e-02,  3.98813635e-02,\n",
       "        -4.10078513e-03, -4.67007831e-02,  8.96593854e-02,\n",
       "         1.55497994e-02,  1.87595170e-02, -4.88698855e-02,\n",
       "        -2.92499866e-02, -6.25091791e-03,  2.03196108e-02,\n",
       "        -3.55663486e-02, -3.73998210e-02,  1.84038598e-02,\n",
       "        -5.25979921e-02,  8.15077573e-02,  4.60509807e-02,\n",
       "        -1.32102957e-02,  3.01549416e-02,  4.76487204e-02,\n",
       "        -3.27088162e-02, -1.27562424e-02, -6.99034845e-03,\n",
       "        -7.11427778e-02, -1.01690087e-02,  2.19323300e-02,\n",
       "        -1.86751932e-02, -9.12576728e-03, -7.94968084e-02,\n",
       "         1.33223808e-03, -3.16991806e-02,  3.49547118e-02,\n",
       "         1.72769371e-02,  5.60832545e-02, -1.54097397e-02,\n",
       "        -3.99774946e-02, -6.01975545e-02, -2.27179262e-03,\n",
       "        -3.08658853e-02,  1.53021999e-02,  5.55908494e-02,\n",
       "         3.24415863e-02, -7.35184774e-02,  3.62773836e-02,\n",
       "         3.22114155e-02,  7.08634704e-02,  4.67931889e-02,\n",
       "        -4.20141257e-02,  8.63749012e-02,  5.02916761e-02,\n",
       "         1.34052883e-03,  1.32239033e-02,  2.17537098e-02,\n",
       "         5.76668680e-02, -2.23725252e-02,  2.19557714e-02,\n",
       "         5.48404176e-03,  3.59007567e-02,  7.97095243e-03,\n",
       "        -1.98859014e-02,  6.18830994e-02,  9.05574337e-02,\n",
       "        -9.30584967e-02, -7.32758269e-02,  8.01822077e-03,\n",
       "         5.56061529e-02, -3.14804949e-02,  5.23047298e-02,\n",
       "         7.15279803e-02,  1.01781720e-02, -1.54208178e-02,\n",
       "        -4.46068086e-02, -1.51347136e-03, -2.09792312e-02,\n",
       "         4.27211113e-02, -9.80552100e-03, -4.04786468e-02,\n",
       "         3.60271223e-02,  3.17446887e-04, -6.44080061e-03,\n",
       "         4.31138799e-02,  4.72383797e-02,  4.89000529e-02,\n",
       "        -6.52453825e-02,  7.51738027e-02, -4.74157520e-02,\n",
       "        -1.72632933e-02,  1.00335293e-02,  5.18157445e-02,\n",
       "        -4.35576215e-02, -9.79175232e-03, -2.53801309e-02,\n",
       "        -2.14432459e-03, -3.49023566e-02, -3.08152009e-02,\n",
       "        -5.93857700e-03,  7.65208974e-02, -5.86165255e-03,\n",
       "         2.14289948e-02, -1.11306906e-02,  4.92087267e-02,\n",
       "         7.58670717e-02,  1.38521371e-02, -6.43145666e-03,\n",
       "        -1.46237074e-03, -5.92104271e-02, -6.28452469e-03,\n",
       "         3.20171081e-02,  9.35658067e-02, -5.44565544e-02,\n",
       "        -2.45495085e-02, -5.81423240e-03,  6.71940222e-02,\n",
       "         3.44727747e-02,  2.23616995e-02,  9.88731347e-03,\n",
       "         6.22731149e-02, -7.65978843e-02, -6.31301701e-02,\n",
       "        -4.87902574e-02, -2.03955509e-02,  6.41497672e-02,\n",
       "         2.74396874e-02,  4.25702780e-02,  3.12294941e-02,\n",
       "        -1.07161542e-02, -2.93256603e-02, -5.03539741e-02,\n",
       "        -8.30472633e-02, -1.96954329e-02, -2.83349473e-02,\n",
       "         6.71453252e-02, -2.62972061e-02,  1.97073147e-02,\n",
       "        -1.38235732e-03, -2.94613689e-02,  4.57599899e-03,\n",
       "         3.07568000e-03, -3.23810615e-02, -1.91748980e-02,\n",
       "        -4.36742269e-02,  7.35994875e-02,  1.26769794e-02,\n",
       "        -6.85494067e-03,  3.15215401e-02,  5.03265597e-02,\n",
       "         2.84530362e-03, -3.66412215e-02, -8.62077773e-02,\n",
       "         2.98984721e-02, -1.22807613e-02,  3.98886576e-02,\n",
       "        -4.55864938e-03, -8.30078423e-02,  9.53644700e-03,\n",
       "         3.74850421e-03, -1.67448130e-02,  8.22941400e-03,\n",
       "         5.84294423e-02,  2.37853676e-02, -1.03838509e-02,\n",
       "         4.75051925e-02,  3.80803831e-02, -1.91668738e-02,\n",
       "         4.33117561e-02,  3.96541283e-02, -3.55137698e-02,\n",
       "         5.91595173e-02,  3.92497629e-02,  1.14543801e-02,\n",
       "         1.89083200e-02,  3.35725173e-02,  7.47825950e-03,\n",
       "         6.17328938e-03, -6.42362013e-02, -8.87807161e-02,\n",
       "         4.74980809e-02, -6.59913011e-03, -7.97121003e-02,\n",
       "         9.77682248e-02,  9.60132554e-02, -3.04143764e-02,\n",
       "         7.81931728e-02, -2.20839051e-03,  6.76240772e-03,\n",
       "        -1.14674509e-01,  3.97722162e-02, -2.15659980e-02,\n",
       "         2.85186917e-02,  2.32248399e-02, -5.37882047e-03,\n",
       "        -2.53044143e-02,  6.29684776e-02, -2.37390194e-02,\n",
       "         8.61139297e-02, -9.54941753e-03, -1.20456272e-04,\n",
       "        -3.36731374e-02, -1.36827938e-02, -1.36038079e-03,\n",
       "         2.06673332e-02,  3.42826522e-03, -6.69976417e-03,\n",
       "        -2.05111466e-02, -1.88630987e-02, -2.15534791e-02,\n",
       "        -3.07980459e-02,  1.96437150e-01, -9.43347532e-03,\n",
       "        -6.41500205e-02,  4.36109975e-02,  7.85774738e-02,\n",
       "        -6.17987197e-03, -1.19607355e-02, -3.26143694e-03,\n",
       "        -3.75980176e-02,  5.35216294e-02, -3.47525291e-02,\n",
       "        -4.24852334e-02,  2.65144669e-02,  7.03585893e-02,\n",
       "        -4.99901660e-02, -9.61206481e-02,  2.16493513e-02,\n",
       "         7.11158812e-02,  3.91186923e-02,  1.26844896e-02,\n",
       "        -1.71887167e-02,  5.66412024e-02,  3.76448296e-02,\n",
       "         9.95458849e-03, -9.64869745e-03, -9.62863211e-03,\n",
       "        -4.75918315e-02,  2.48251688e-02, -1.88114848e-02,\n",
       "         5.07317260e-02,  5.11781219e-03, -5.33853322e-02,\n",
       "         4.78216596e-02,  1.85684868e-04]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = rt.InferenceSession(\"encoder/universal-sentence-encoder-5.onnx\", opt, providers=ONNX_PROVIDERS)\n",
    "\n",
    "sess.run(\n",
    "    output_names=[\"outputs\"],\n",
    "    input_feed={\"inputs:0\": [span]},\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512c0c99",
   "metadata": {},
   "source": [
    "## 4. Exporting and optimizing GPT-Neo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc4a292c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "429a06cf904448b3b2fc573ee4562499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.35k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e88d17ed6850420a8d076a73877c428b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/5.31G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22594e21e6da439a9f8496bb38e044ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68ab302662e045e79d929099c20015d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c90c1a8fa14566b8e76af9aac87a6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "984079127abf406db05dbf7e6641bdad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/200 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"EleutherAI/gpt-neo-1.3B\"\n",
    "pipeline_name = \"text-generation\"\n",
    "\n",
    "model_pth = Path(f\"gpt_neo/gpt_neo_13b.onnx\")\n",
    "model_pth.parent.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "nlp = transformers.pipeline(pipeline_name, model=model_name, tokenizer=model_name, device=0)\n",
    "tokenizer = nlp.tokenizer\n",
    "model = nlp.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53f61113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 ms ± 9.73 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "inp = tokenizer(span, return_tensors=\"pt\")\n",
    "for key, value in inp.items():\n",
    "    inp[key] = value.to(\"cuda\")\n",
    "with torch.no_grad():\n",
    "    out = nlp.model.forward(**inp).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af7edef7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input, output and indices must be on the current device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-35425f7cfb9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mdynamic_axes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     ) = convert_graph_to_onnx.infer_shapes(nlp, \"pt\")\n\u001b[0m\u001b[1;32m      8\u001b[0m     ordered_input_names, model_args = convert_graph_to_onnx.ensure_valid_input(\n\u001b[1;32m      9\u001b[0m         \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/convert_graph_to_onnx.py\u001b[0m in \u001b[0;36minfer_shapes\u001b[0;34m(nlp, framework)\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"This is a sample output\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mseq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModelOutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/gpt_neo/modeling_gpt_neo.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m         transformer_outputs = self.transformer(\n\u001b[0m\u001b[1;32m    909\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/gpt_neo/modeling_gpt_neo.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwte\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m         \u001b[0mposition_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwpe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mposition_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1914\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1916\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input, output and indices must be on the current device"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    (\n",
    "        input_names,\n",
    "        output_names,\n",
    "        dynamic_axes,\n",
    "        tokens,\n",
    "    ) = convert_graph_to_onnx.infer_shapes(nlp, \"pt\")\n",
    "    ordered_input_names, model_args = convert_graph_to_onnx.ensure_valid_input(\n",
    "        nlp.model, tokens, input_names\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7ea977",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTNeoSent(transformers.GPTNeoForCausalLM):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.sentence_embedding = torch.nn.Identity()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        return self.sentence_embedding(\n",
    "            super().forward(input_ids, attention_mask=attention_mask).logits\n",
    "        )\n",
    "# Create the new model based on the config of the original pipeline\n",
    "model = GPTNeoSent(config=nlp.model.config).from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c646a00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "model.forward(**nlp.tokenizer([span], return_tensors=\"pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7c72ad",
   "metadata": {},
   "source": [
    "# Warning! This step may take an hour or even more. Use ate own discretion!"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6fd2b52c",
   "metadata": {
    "tags": []
   },
   "source": [
    "encoding = nlp.tokenizer([span], return_tensors=\"pt\")\n",
    "\n",
    "if not model_pth.exists():\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        (encoding[\"input_ids\"], encoding[\"attention_mask\"]),\n",
    "        f=model_pth.as_posix(),\n",
    "        input_names=input_names,\n",
    "        output_names=output_names,\n",
    "        dynamic_axes=dynamic_axes,\n",
    "        do_constant_folding=True,\n",
    "        use_external_data_format=True,\n",
    "        enable_onnx_checker=True,\n",
    "        opset_version=12,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "53dd0c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt_neo/\n",
      "gpt_neo/transformer.h.4.attn.attention.bias\n",
      "gpt_neo/154931\n",
      "gpt_neo/150389\n",
      "gpt_neo/transformer.h.1.attn.attention.out_proj.bias\n",
      "gpt_neo/transformer.h.23.ln_1.bias\n",
      "gpt_neo/154935\n",
      "gpt_neo/161766\n",
      "gpt_neo/148101\n",
      "gpt_neo/145833\n",
      "gpt_neo/transformer.h.15.ln_1.weight\n",
      "gpt_neo/143554\n",
      "gpt_neo/transformer.h.19.ln_1.bias\n",
      "gpt_neo/159501\n",
      "gpt_neo/136712\n",
      "gpt_neo/transformer.wpe.weight\n",
      "gpt_neo/152654\n",
      "gpt_neo/152666\n",
      "gpt_neo/transformer.h.23.ln_2.bias\n",
      "gpt_neo/transformer.h.4.attn.attention.out_proj.bias\n",
      "gpt_neo/transformer.h.17.attn.attention.out_proj.bias\n",
      "gpt_neo/152670\n",
      "gpt_neo/transformer.h.23.ln_2.weight\n",
      "gpt_neo/transformer.h.9.mlp.c_proj.bias\n",
      "gpt_neo/141267\n",
      "gpt_neo/transformer.h.11.ln_2.weight\n",
      "gpt_neo/150380\n",
      "gpt_neo/transformer.h.20.mlp.c_proj.bias\n",
      "gpt_neo/148110\n",
      "gpt_neo/transformer.h.21.mlp.c_fc.bias\n",
      "gpt_neo/157214\n",
      "gpt_neo/transformer.h.22.attn.attention.out_proj.bias\n",
      "gpt_neo/transformer.h.10.attn.attention.bias\n",
      "gpt_neo/transformer.h.6.ln_1.weight\n",
      "gpt_neo/transformer.h.13.ln_1.weight\n",
      "gpt_neo/143558\n",
      "gpt_neo/161778\n",
      "gpt_neo/161770\n",
      "gpt_neo/transformer.h.14.mlp.c_fc.bias\n",
      "gpt_neo/161765\n",
      "gpt_neo/transformer.h.2.mlp.c_fc.bias\n",
      "gpt_neo/148111\n",
      "gpt_neo/161769\n",
      "gpt_neo/150391\n",
      "gpt_neo/transformer.h.15.mlp.c_proj.bias\n",
      "gpt_neo/transformer.h.2.attn.attention.out_proj.bias\n",
      "gpt_neo/transformer.h.14.ln_2.bias\n",
      "gpt_neo/transformer.h.3.mlp.c_proj.bias\n",
      "gpt_neo/transformer.h.13.ln_2.bias\n",
      "gpt_neo/transformer.h.16.ln_1.weight\n",
      "gpt_neo/154936\n",
      "gpt_neo/154946\n",
      "gpt_neo/transformer.h.5.ln_1.weight\n",
      "gpt_neo/transformer.h.10.attn.attention.out_proj.bias\n",
      "gpt_neo/transformer.h.11.attn.attention.out_proj.bias\n",
      "gpt_neo/transformer.h.20.ln_1.bias\n",
      "gpt_neo/transformer.h.4.ln_1.weight\n",
      "gpt_neo/138989\n",
      "gpt_neo/transformer.h.8.attn.attention.bias\n",
      "gpt_neo/143556\n",
      "gpt_neo/transformer.h.11.ln_2.bias\n",
      "gpt_neo/143555\n",
      "gpt_neo/154944\n",
      "gpt_neo/141276\n",
      "gpt_neo/148098\n",
      "gpt_neo/136724\n",
      "gpt_neo/136725\n",
      "gpt_neo/164044\n",
      "gpt_neo/transformer.h.5.attn.attention.out_proj.bias\n",
      "gpt_neo/transformer.h.16.ln_2.weight\n",
      "gpt_neo/transformer.h.6.attn.attention.out_proj.bias\n",
      "gpt_neo/148102\n",
      "gpt_neo/141268\n",
      "gpt_neo/161782\n",
      "gpt_neo/transformer.h.2.ln_2.bias\n",
      "gpt_neo/transformer.h.1.mlp.c_fc.bias\n",
      "gpt_neo/transformer.h.22.mlp.c_proj.bias\n",
      "gpt_neo/161779\n",
      "gpt_neo/161768\n",
      "gpt_neo/transformer.h.5.ln_2.bias\n",
      "gpt_neo/transformer.h.18.ln_2.bias\n",
      "gpt_neo/transformer.h.22.ln_1.bias\n",
      "gpt_neo/136722\n",
      "gpt_neo/transformer.h.12.ln_1.bias\n",
      "gpt_neo/145832\n",
      "gpt_neo/transformer.h.13.attn.attention.out_proj.bias\n",
      "gpt_neo/143542\n",
      "gpt_neo/transformer.h.17.mlp.c_fc.bias\n",
      "gpt_neo/transformer.h.10.ln_1.weight\n",
      "gpt_neo/transformer.h.18.attn.attention.out_proj.bias\n",
      "gpt_neo/transformer.h.4.ln_1.bias\n",
      "gpt_neo/transformer.h.14.attn.attention.bias\n",
      "gpt_neo/159505\n",
      "gpt_neo/transformer.wte.weight\n",
      "gpt_neo/transformer.h.11.mlp.c_proj.bias\n",
      "gpt_neo/transformer.h.19.mlp.c_fc.bias\n",
      "gpt_neo/transformer.h.16.mlp.c_proj.bias\n",
      "gpt_neo/transformer.h.4.mlp.c_fc.bias\n",
      "gpt_neo/159504\n",
      "gpt_neo/transformer.h.2.ln_1.bias\n",
      "gpt_neo/150393\n",
      "gpt_neo/transformer.h.3.ln_2.bias\n",
      "gpt_neo/transformer.h.16.attn.attention.out_proj.bias\n",
      "gpt_neo/141263\n",
      "gpt_neo/transformer.h.14.mlp.c_proj.bias\n",
      "gpt_neo/transformer.h.8.attn.attention.out_proj.bias\n",
      "gpt_neo/transformer.h.8.ln_2.weight\n",
      "gpt_neo/161781\n",
      "gpt_neo/157226\n",
      "gpt_neo/152657\n",
      "gpt_neo/transformer.h.14.attn.attention.out_proj.bias\n",
      "gpt_neo/transformer.h.19.mlp.c_proj.bias\n",
      "gpt_neo/transformer.h.9.ln_1.weight\n",
      "gpt_neo/145821\n",
      "gpt_neo/transformer.h.1.ln_2.weight\n",
      "gpt_neo/gpt_neo_13b.onnx\n",
      "gpt_neo/transformer.h.18.ln_1.weight\n",
      "gpt_neo/136710\n",
      "gpt_neo/transformer.h.3.ln_2.weight\n",
      "gpt_neo/transformer.h.20.ln_1.weight\n",
      "gpt_neo/transformer.h.8.ln_1.bias\n",
      "gpt_neo/transformer.h.16.ln_1.bias\n",
      "gpt_neo/transformer.h.9.ln_2.weight\n",
      "gpt_neo/159488\n",
      "gpt_neo/transformer.h.12.ln_2.weight\n",
      "gpt_neo/transformer.h.20.ln_2.bias\n",
      "gpt_neo/154947\n",
      "gpt_neo/transformer.h.13.ln_2.weight\n",
      "gpt_neo/transformer.h.5.ln_2.weight\n",
      "gpt_neo/transformer.h.17.ln_2.weight\n",
      "gpt_neo/transformer.h.19.ln_1.weight\n",
      "gpt_neo/transformer.h.15.attn.attention.out_proj.bias\n",
      "gpt_neo/transformer.h.1.ln_1.weight\n",
      "gpt_neo/154945\n",
      "gpt_neo/139000\n",
      "gpt_neo/transformer.h.2.ln_2.weight\n",
      "gpt_neo/138985\n",
      "gpt_neo/150377\n",
      "gpt_neo/136721\n",
      "gpt_neo/159487\n",
      "gpt_neo/157211\n",
      "gpt_neo/transformer.h.21.ln_1.weight\n",
      "gpt_neo/transformer.h.14.ln_1.bias\n",
      "gpt_neo/transformer.h.8.ln_2.bias\n",
      "gpt_neo/148099\n",
      "gpt_neo/150375\n",
      "gpt_neo/transformer.h.18.attn.attention.bias\n",
      "gpt_neo/141278\n",
      "gpt_neo/145822\n",
      "gpt_neo/139001\n",
      "gpt_neo/157223\n",
      "gpt_neo/transformer.h.7.ln_1.weight\n",
      "gpt_neo/transformer.h.5.ln_1.bias\n",
      "gpt_neo/152658\n",
      "gpt_neo/transformer.h.11.ln_1.weight\n",
      "gpt_neo/transformer.h.16.mlp.c_fc.bias\n",
      "gpt_neo/transformer.h.6.ln_2.weight\n",
      "gpt_neo/143543\n",
      "gpt_neo/transformer.h.1.ln_2.bias\n",
      "gpt_neo/transformer.h.15.mlp.c_fc.bias\n",
      "gpt_neo/transformer.h.20.mlp.c_fc.bias\n",
      "gpt_neo/136723\n",
      "gpt_neo/transformer.h.12.ln_2.bias\n",
      "gpt_neo/150378\n",
      "gpt_neo/157227\n",
      "gpt_neo/161767\n",
      "gpt_neo/143545\n",
      "gpt_neo/transformer.h.18.mlp.c_fc.bias\n",
      "gpt_neo/148100\n",
      "gpt_neo/152656\n",
      "gpt_neo/154949\n",
      "gpt_neo/transformer.h.16.attn.attention.bias\n",
      "gpt_neo/148112\n",
      "gpt_neo/154932\n",
      "gpt_neo/transformer.h.6.attn.attention.bias\n",
      "gpt_neo/141279\n",
      "gpt_neo/transformer.h.15.ln_2.bias\n",
      "gpt_neo/transformer.h.13.mlp.c_fc.bias\n",
      "gpt_neo/159492\n",
      "gpt_neo/transformer.h.21.ln_1.bias\n",
      "gpt_neo/143557\n",
      "gpt_neo/transformer.h.20.attn.attention.bias\n",
      "gpt_neo/138988\n",
      "gpt_neo/transformer.h.10.ln_1.bias\n",
      "gpt_neo/138987\n",
      "gpt_neo/transformer.h.17.ln_1.weight\n",
      "gpt_neo/150376\n",
      "gpt_neo/transformer.ln_f.weight\n",
      "gpt_neo/159503\n",
      "gpt_neo/transformer.h.4.mlp.c_proj.bias\n",
      "gpt_neo/transformer.h.7.ln_1.bias\n",
      "gpt_neo/transformer.h.0.ln_2.weight\n",
      "gpt_neo/transformer.h.1.ln_1.bias\n",
      "gpt_neo/transformer.h.7.ln_2.bias\n",
      "gpt_neo/157209\n",
      "gpt_neo/136711\n",
      "gpt_neo/141265\n",
      "gpt_neo/141266\n",
      "gpt_neo/157212\n",
      "gpt_neo/transformer.h.17.ln_2.bias\n",
      "gpt_neo/transformer.h.2.mlp.c_proj.bias\n",
      "gpt_neo/transformer.h.21.ln_2.bias\n",
      "gpt_neo/159500\n",
      "gpt_neo/154948\n",
      "gpt_neo/transformer.h.21.mlp.c_proj.bias\n",
      "gpt_neo/transformer.h.19.attn.attention.out_proj.bias\n",
      "gpt_neo/159490\n",
      "gpt_neo/143541\n",
      "gpt_neo/141277\n",
      "gpt_neo/141281\n",
      "gpt_neo/145823\n",
      "gpt_neo/161783\n",
      "gpt_neo/152653\n",
      "gpt_neo/transformer.h.10.mlp.c_fc.bias\n",
      "gpt_neo/transformer.h.0.mlp.c_fc.bias\n",
      "gpt_neo/transformer.h.20.attn.attention.out_proj.bias\n",
      "gpt_neo/164046\n",
      "gpt_neo/transformer.h.13.ln_1.bias\n",
      "gpt_neo/transformer.h.5.mlp.c_proj.bias\n",
      "gpt_neo/transformer.h.7.ln_2.weight\n",
      "gpt_neo/154934\n",
      "gpt_neo/150388\n",
      "gpt_neo/transformer.h.21.ln_2.weight\n",
      "gpt_neo/145836\n",
      "gpt_neo/transformer.h.3.ln_1.bias\n",
      "gpt_neo/transformer.h.23.ln_1.weight\n",
      "gpt_neo/148097\n",
      "gpt_neo/145834\n",
      "gpt_neo/138999\n",
      "gpt_neo/transformer.h.10.ln_2.weight\n",
      "gpt_neo/transformer.h.6.mlp.c_proj.bias\n",
      "gpt_neo/transformer.h.8.ln_1.weight\n",
      "gpt_neo/transformer.h.6.ln_1.bias\n",
      "gpt_neo/transformer.h.7.attn.attention.out_proj.bias\n",
      "gpt_neo/145824\n",
      "gpt_neo/150390\n",
      "gpt_neo/transformer.h.3.mlp.c_fc.bias\n",
      "gpt_neo/transformer.h.22.ln_2.weight\n",
      "gpt_neo/transformer.h.14.ln_2.weight\n",
      "gpt_neo/159491\n",
      "gpt_neo/157224\n",
      "gpt_neo/transformer.h.23.attn.attention.out_proj.bias\n",
      "gpt_neo/transformer.h.0.ln_1.weight\n",
      "gpt_neo/139002\n",
      "gpt_neo/139003\n",
      "gpt_neo/154933\n",
      "gpt_neo/145819\n",
      "gpt_neo/transformer.h.15.ln_2.weight\n",
      "gpt_neo/transformer.h.17.ln_1.bias\n",
      "gpt_neo/transformer.h.7.mlp.c_proj.bias\n",
      "gpt_neo/transformer.h.12.mlp.c_fc.bias\n",
      "gpt_neo/150392\n",
      "gpt_neo/141280\n",
      "gpt_neo/138986\n",
      "gpt_neo/transformer.h.22.mlp.c_fc.bias\n",
      "gpt_neo/145835\n",
      "gpt_neo/transformer.h.12.attn.attention.out_proj.bias\n",
      "gpt_neo/transformer.h.2.ln_1.weight\n",
      "gpt_neo/transformer.h.23.mlp.c_fc.bias\n",
      "gpt_neo/161780\n",
      "gpt_neo/transformer.h.13.mlp.c_proj.bias\n",
      "gpt_neo/152655\n",
      "gpt_neo/transformer.ln_f.bias\n",
      "gpt_neo/transformer.h.2.attn.attention.bias\n",
      "gpt_neo/transformer.h.9.attn.attention.out_proj.bias\n",
      "gpt_neo/157225\n",
      "gpt_neo/transformer.h.9.mlp.c_fc.bias\n",
      "gpt_neo/transformer.h.9.ln_1.bias\n",
      "gpt_neo/148113\n",
      "gpt_neo/transformer.h.5.mlp.c_fc.bias\n",
      "gpt_neo/transformer.h.22.ln_2.bias\n",
      "gpt_neo/transformer.h.14.ln_1.weight\n",
      "gpt_neo/transformer.h.0.attn.attention.out_proj.bias\n",
      "gpt_neo/141264\n",
      "gpt_neo/transformer.h.16.ln_2.bias\n",
      "gpt_neo/transformer.h.3.ln_1.weight\n",
      "gpt_neo/152668\n",
      "gpt_neo/164045\n",
      "gpt_neo/transformer.h.4.ln_2.bias\n",
      "gpt_neo/150379\n",
      "gpt_neo/transformer.h.0.ln_1.bias\n",
      "gpt_neo/157222\n",
      "gpt_neo/transformer.h.12.mlp.c_proj.bias\n",
      "gpt_neo/transformer.h.6.ln_2.bias\n",
      "gpt_neo/152667\n",
      "gpt_neo/143559\n",
      "gpt_neo/164043\n",
      "gpt_neo/transformer.h.21.attn.attention.out_proj.bias\n",
      "gpt_neo/transformer.h.12.attn.attention.bias\n",
      "gpt_neo/transformer.h.19.ln_2.weight\n",
      "gpt_neo/transformer.h.1.mlp.c_proj.bias\n",
      "gpt_neo/145820\n",
      "gpt_neo/transformer.h.12.ln_1.weight\n",
      "gpt_neo/143544\n",
      "gpt_neo/transformer.h.15.ln_1.bias\n",
      "gpt_neo/transformer.h.7.mlp.c_fc.bias\n",
      "gpt_neo/136720\n",
      "gpt_neo/159489\n",
      "gpt_neo/148115\n",
      "gpt_neo/138998\n",
      "gpt_neo/159502\n",
      "gpt_neo/transformer.h.9.ln_2.bias\n",
      "gpt_neo/transformer.h.19.ln_2.bias\n",
      "gpt_neo/transformer.h.6.mlp.c_fc.bias\n",
      "gpt_neo/transformer.h.23.mlp.c_proj.bias\n",
      "gpt_neo/transformer.h.0.ln_2.bias\n",
      "gpt_neo/145837\n",
      "gpt_neo/transformer.h.18.mlp.c_proj.bias\n",
      "gpt_neo/transformer.h.11.ln_1.bias\n",
      "gpt_neo/transformer.h.10.ln_2.bias\n",
      "gpt_neo/transformer.h.17.mlp.c_proj.bias\n",
      "gpt_neo/transformer.h.22.ln_1.weight\n",
      "gpt_neo/157210\n",
      "gpt_neo/transformer.h.0.mlp.c_proj.bias\n",
      "gpt_neo/transformer.h.18.ln_1.bias\n",
      "gpt_neo/transformer.h.0.attn.attention.bias\n",
      "gpt_neo/143546\n",
      "gpt_neo/transformer.h.4.ln_2.weight\n",
      "gpt_neo/157213\n",
      "gpt_neo/transformer.h.8.mlp.c_proj.bias\n",
      "gpt_neo/152671\n",
      "gpt_neo/152669\n",
      "gpt_neo/148114\n",
      "gpt_neo/138990\n",
      "gpt_neo/transformer.h.8.mlp.c_fc.bias\n",
      "gpt_neo/transformer.h.18.ln_2.weight\n",
      "gpt_neo/transformer.h.20.ln_2.weight\n",
      "gpt_neo/transformer.h.10.mlp.c_proj.bias\n",
      "gpt_neo/transformer.h.3.attn.attention.out_proj.bias\n",
      "gpt_neo/transformer.h.11.mlp.c_fc.bias\n",
      "gpt_neo/transformer.h.22.attn.attention.bias\n"
     ]
    }
   ],
   "source": [
    "# We are using a pre-exported model here.\n",
    "!tar -xvzf gpt_neo.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ee7ceee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 56s, sys: 3.64 s, total: 3min\n",
      "Wall time: 2min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sess = rt.InferenceSession(\n",
    "    str(model_pth), \n",
    "    opt,\n",
    "    providers=ONNX_PROVIDERS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3cd0b089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310 ms ± 8.57 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "model_input = tokenizer.encode_plus(span)\n",
    "model_input = {name : np.atleast_2d(value) for name, value in model_input.items()}\n",
    "onnx_result = sess.run(None, model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4e9bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "del sess"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
